name: "train_seg_Full_anno"

input: 'data'
input_shape { dim:1 dim: 3 dim: 320 dim: 320 }
input: "cls-label"
input_shape { dim:1  dim: 80   dim: 1  dim: 1}


# 224 x 224
# conv1_1
layer {  bottom: "data"  top: "conv1_1"  name: "conv1_1"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 64    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv1_1"  top: "conv1_1"  name: "relu1_1"  type: "ReLU"}
# conv1_2
layer {  bottom: "conv1_1"  top: "conv1_2"  name: "conv1_2"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 64    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv1_2"  top: "conv1_2"  name: "relu1_2"  type: "ReLU"}

# pool1
layer {
  bottom: "conv1_2"  top: "pool1" top: "pool1_mask" name: "pool1"  type: "Pooling"
  pooling_param {    pool: MAX    kernel_size: 2    stride: 2  }
}

# 112 x 112
# conv2_1
layer {  bottom: "pool1"  top: "conv2_1"  name: "conv2_1"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 128    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv2_1"  top: "conv2_1"  name: "relu2_1"  type: "ReLU"}
# conv2_2
layer {  bottom: "conv2_1"  top: "conv2_2"  name: "conv2_2"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 128    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv2_2"  top: "conv2_2"  name: "relu2_2"  type: "ReLU"}

# pool2
layer {
  bottom: "conv2_2"  top: "pool2" top: "pool2_mask" name: "pool2"  type: "Pooling"
  pooling_param {    pool: MAX    kernel_size: 2    stride: 2  }
}

# 56 x 56
# conv3_1
layer {  bottom: "pool2"  top: "conv3_1"  name: "conv3_1"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 256    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv3_1"  top: "conv3_1"  name: "relu3_1"  type: "ReLU"}
# conv3_2
layer {  bottom: "conv3_1"  top: "conv3_2"  name: "conv3_2"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 256    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv3_2"  top: "conv3_2"  name: "relu3_2"  type: "ReLU"}
# conv3_3
layer {  bottom: "conv3_2"  top: "conv3_3"  name: "conv3_3"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 256    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv3_3"  top: "conv3_3"  name: "relu3_3"  type: "ReLU"}

# pool3
layer {
  bottom: "conv3_3"  top: "pool3" top: "pool3_mask" name: "pool3"  type: "Pooling"
  pooling_param {    pool: MAX    kernel_size: 2    stride: 2  }
}

# 28 x 28
# conv4_1
layer {  bottom: "pool3"  top: "conv4_1"  name: "conv4_1"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 512    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv4_1"  top: "conv4_1"  name: "relu4_1"  type: "ReLU"}
# conv4_2
layer {  bottom: "conv4_1"  top: "conv4_2"  name: "conv4_2"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 512    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv4_2"  top: "conv4_2"  name: "relu4_2"  type: "ReLU"}
# conv4_3
layer {  bottom: "conv4_2"  top: "conv4_3"  name: "conv4_3"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 512    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv4_3"  top: "conv4_3"  name: "relu4_3"  type: "ReLU"}

# pool4
layer {
  bottom: "conv4_3"  top: "pool4" top: "pool4_mask"  name: "pool4"  type: "Pooling"
  pooling_param {    pool: MAX    kernel_size: 2    stride: 2  }
}

# 14 x 14
# conv5_1
layer {  bottom: "pool4"  top: "conv5_1"  name: "conv5_1"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 512    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv5_1"  top: "conv5_1"  name: "relu5_1"  type: "ReLU"}
# conv5_2
layer {  bottom: "conv5_1"  top: "conv5_2"  name: "conv5_2"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 512    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv5_2"  top: "conv5_2"  name: "relu5_2"  type: "ReLU"}
# conv5_3
layer {  bottom: "conv5_2"  top: "conv5_3"  name: "conv5_3"  type: "Convolution"
  param{ lr_mult: 0 decay_mult: 1}
  param{ lr_mult: 0  decay_mult: 0}
  convolution_param {    num_output: 512    pad: 1    kernel_size: 3  }}
layer {  bottom: "conv5_3"  top: "conv5_3"  name: "relu5_3"  type: "ReLU"}

# scale activations approximately between 0 and 1
layer {
  name: "soft-att"
  type: "Scale"
  bottom: "conv5_3"
  scale_param { scale_factor: 0.004 } # no scaling
  top: "conv5_3_scaled"
}

# embed feature
layer { bottom: 'conv5_3_scaled' top: 'feat_embed' name: 'feat_embed' type: "InnerProduct"
  param{ lr_mult: 1 decay_mult: 1}
  param{ lr_mult: 2  decay_mult: 0}
  inner_product_param {   num_output: 1024
    weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }}}

# embed class label
layer { bottom: 'cls-label' top: 'cls_embed' name: 'cls_embed' type: "InnerProduct"
  param{ lr_mult: 1 decay_mult: 1}
  param{ lr_mult: 2  decay_mult: 0}
  inner_product_param {   num_output: 1024
    weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }}}

# multiplicative
layer { bottom: "cls_embed" bottom: "feat_embed" top: "multiplicative" name: "multiplicative" type: "Eltwise"
  eltwise_param {   operation: PROD } }

# combine two feature
layer { bottom: 'multiplicative' top: 'combined_embed' name: 'combined_embed' type: "InnerProduct"
  param{ lr_mult: 1 decay_mult: 1}
  param{ lr_mult: 2  decay_mult: 0}
  inner_product_param {   num_output: 1024
    weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }}}
layer {  bottom: "combined_embed"  top: "combined_embed"  name: "relu_combined"  type: "ReLU"}

# generate attention
layer {
  name: "att-w"
  type: "InnerProduct"
  bottom: "combined_embed"
  top: "att-w"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 400
    weight_filler {
     # type: "xavier"
      type: 'gaussian'  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "att-normalized"
  type: "Softmax"
  bottom: "att-w"
  top: "att-normalized"
}

layer {
  name: "att-reshape"
  type: "Reshape"
  bottom: "att-normalized"
  top: "att"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 20
      dim: 20
    }
  }
}

layer {
  name: "soft-att"
  type: "LinearSum"
  bottom: "conv5_3_scaled"
  bottom: "att"
  top: "soft-att"
}


# decoder

######### ENCODER - DECODER Interface
##### 1. Slice the source data
# 1-1. attention
layer {
  name: "filter_sum"
  type: "FilterSum"
  bottom: "conv5_3_scaled"
  bottom: "soft-att"
  top: "filter_sum_map"
}

######### DECODER
# deconv5_1
layer { bottom: 'filter_sum_map' top: 'deconv5_1' name: 'deconv5_1' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output: 512   pad: 1  kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv5_1' top: 'deconv5_1' name: 'derelu5_1' type: "ReLU" }



# unpool4
layer { type: "Unpooling"  bottom: "deconv5_1"  bottom: "pool4_mask"  top: "unpool4"  name: "unpool4"
  unpooling_param {   unpool: MAX   kernel_size: 2    stride: 2   unpool_size: 40 }
}

# 28 x 28
# deconv4_1
layer { bottom: 'unpool4' top: 'deconv4_1' name: 'deconv4_1' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output: 512   pad: 1  kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv4_1' top: 'deconv4_1' name: 'derelu4_1' type: "ReLU" }
# deconv 4_2
layer { bottom: 'deconv4_1' top: 'deconv4_2' name: 'deconv4_2' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output: 512   pad: 1  kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv4_2' top: 'deconv4_2' name: 'derelu4_2' type: "ReLU" }
# deconv 4_3
layer { bottom: 'deconv4_2' top: 'deconv4_3' name: 'deconv4_3' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output: 256   pad: 1  kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv4_3' top: 'deconv4_3' name: 'derelu4_3' type: "ReLU" }

# unpool3
layer { type: "Unpooling"  bottom: "deconv4_3"  bottom: "pool3_mask"  top: "unpool3"  name: "unpool3"
  unpooling_param {   unpool: MAX   kernel_size: 2    stride: 2   unpool_size: 80 }
}

# 56 x 56
# deconv3_1
layer { bottom: 'unpool3' top: 'deconv3_1' name: 'deconv3_1' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output:256    pad:1   kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv3_1' top: 'deconv3_1' name: 'derelu3_1' type: "ReLU" }
# deconv3_2
layer { bottom: 'deconv3_1' top: 'deconv3_2' name: 'deconv3_2' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output:256    pad:1   kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv3_2' top: 'deconv3_2' name: 'derelu3_2' type: "ReLU" }
# deconv3_3
layer { bottom: 'deconv3_2' top: 'deconv3_3' name: 'deconv3_3' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output:128    pad:1   kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv3_3' top: 'deconv3_3' name: 'derelu3_3' type: "ReLU" }

# unpool2
layer { type: "Unpooling"  bottom: "deconv3_3"  bottom: "pool2_mask"  top: "unpool2"  name: "unpool2"
  unpooling_param {   unpool: MAX   kernel_size: 2    stride: 2   unpool_size: 160 }
}

# 112 x 112
# deconv2_1
layer { bottom: 'unpool2' top: 'deconv2_1' name: 'deconv2_1' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output:128    pad:1   kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv2_1' top: 'deconv2_1' name: 'derelu2_1' type: "ReLU" }
# deconv2_2
layer { bottom: 'deconv2_1' top: 'deconv2_2' name: 'deconv2_2' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output:64     pad:1   kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv2_2' top: 'deconv2_2' name: 'derelu2_2' type: "ReLU" }

# unpool1
layer { type: "Unpooling"  bottom: "deconv2_2"  bottom: "pool1_mask"  top: "unpool1"  name: "unpool1"
  unpooling_param {   unpool: MAX   kernel_size: 2    stride: 2   unpool_size: 320 }
}
# deconv1_1
layer { bottom: 'unpool1' top: 'deconv1_1' name: 'deconv1_1' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output:64     pad:1   kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv1_1' top: 'deconv1_1' name: 'derelu1_1' type: "ReLU" }

# deconv1_2
layer { bottom: 'deconv1_1' top: 'deconv1_2' name: 'deconv1_2' type: "Deconvolution"
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output:64     pad:1   kernel_size: 3
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }
layer { bottom: 'deconv1_2' top: 'deconv1_2' name: 'derelu1_2' type: "ReLU" }

# seg-score
layer { name: 'seg-score' type: "Convolution" bottom: 'deconv1_2' top: 'seg-score'
 param{  lr_mult: 1 decay_mult: 1} 
 param{  lr_mult: 2 decay_mult: 0}
  convolution_param { num_output: 2 kernel_size: 1
    weight_filler {      type: "gaussian"      std: 0.01    }
    bias_filler {      type: "constant"      value: 0    }} }

